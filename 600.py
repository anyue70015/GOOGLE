import streamlit as st
import pandas as pd
import numpy as np
import pandas_ta as ta
import ccxt
import requests
import os
from datetime import datetime, timedelta
import pytz
import time

# ==================== 1. é…ç½®ï¼ˆç²¾å‡†å¯¹åº”ä½ çš„è¦æ±‚ï¼‰ ====================
APP_TOKEN = "AT_3H9akFZPvOE98cPrDydWmKM4ndgT3bVH"
USER_UID = "UID_wfbEjBobfoHNLmprN3Pi5nwWb4oM"
LOG_FILE = "resonance_logs.csv"

CRYPTO_LIST = ["BTC", "ETH", "SOL", "SUI", "RENDER", "DOGE", "XRP", "HYPE", "AAVE", "TAO", "XAG", "XAU"]
CONTRACTS = {"TAO", "XAG", "XAU"}

# ä½ è¦æ±‚çš„ä¸¤ç»„å¯¹æ¯”ï¼ˆå•ä½ï¼šåˆ†é’Ÿ -> OKXä»£ç ï¼‰
RESONANCE_GROUPS = {
    "Group1_æ—¥å†…(5-15-60)": ["5m", "15m", "1h"],
    "Group2_è¶‹åŠ¿(15-60-240)": ["15m", "1h", "4h"]
}

# éœ€è¦æŠ“å–çš„æ‰€æœ‰å»é‡å‘¨æœŸ
INTERVALS = sorted(list(set([tf for g in RESONANCE_GROUPS.values() for tf in g])))
BEIJING_TZ = pytz.timezone('Asia/Shanghai')

# ==================== 2. æ ¸å¿ƒå‡½æ•° ====================

def save_log(entry):
    df = pd.DataFrame([entry])
    header = not os.path.exists(LOG_FILE)
    df.to_csv(LOG_FILE, mode='a', index=False, header=header, encoding='utf-8-sig')

def send_wx(title, body):
    try:
        payload = {"appToken": APP_TOKEN, "content": f"{title}\n{body}", "uids": [USER_UID]}
        requests.post("https://wxpusher.zjiecode.com/api/send/message", json=payload, timeout=5)
    except: pass

def calculate_ut_bot(df, sensitivity, atr_period):
    if df.empty or len(df) < 50: return pd.DataFrame()
    df.columns = [str(c).capitalize() for c in df.columns]
    df['atr'] = ta.atr(df['High'], df['Low'], df['Close'], length=atr_period)
    df = df.dropna(subset=['atr']).copy()
    n_loss = sensitivity * df['atr']
    src, trail_stop = df['Close'], np.zeros(len(df))
    for i in range(1, len(df)):
        p = trail_stop[i-1]
        if src.iloc[i] > p and src.iloc[i-1] > p: trail_stop[i] = max(p, src.iloc[i] - n_loss.iloc[i])
        elif src.iloc[i] < p and src.iloc[i-1] < p: trail_stop[i] = min(p, src.iloc[i] + n_loss.iloc[i])
        else: trail_stop[i] = src.iloc[i] - n_loss.iloc[i] if src.iloc[i] > p else src.iloc[i] + n_loss.iloc[i]
    df['ts'] = trail_stop
    df['pos'] = np.where(df['Close'] > df['ts'], "BUY", "SELL")
    df['sig'] = (df['pos'] != df['pos'].shift(1)) # ä¿¡å·å˜æ›´ç‚¹
    return df

# ==================== 3. ä¸»ç¨‹åº ====================
st.set_page_config(page_title="UT Bot ä¸¤ç»„å…±æŒ¯å¯¹æ¯”ç‰ˆ", layout="wide")

if "alert_logs" not in st.session_state:
    st.session_state.alert_logs = pd.read_csv(LOG_FILE).to_dict('records') if os.path.exists(LOG_FILE) else []
if "sent_cache" not in st.session_state:
    st.session_state.sent_cache = set()

ex = ccxt.okx({'enableRateLimit': True})
sens = st.sidebar.slider("æ•æ„Ÿåº¦", 0.5, 3.0, 1.2)
atrp = st.sidebar.slider("ATRå‘¨æœŸ", 5, 20, 10)

# æ•°æ®æŠ“å–
all_data = {}
for base in CRYPTO_LIST:
    sym = f"{base}-USDT-SWAP" if base in CONTRACTS else f"{base}/USDT"
    all_data[base] = {}
    for tf in INTERVALS:
        try:
            bars = ex.fetch_ohlcv(sym, timeframe=tf, limit=100)
            df = pd.DataFrame(bars, columns=['ts','open','high','low','close','volume'])
            df.set_index(pd.to_datetime(df['ts'], unit='ms').dt.tz_localize('UTC'), inplace=True)
            all_data[base][tf] = calculate_ut_bot(df, sens, atrp)
            time.sleep(0.05)
        except: all_data[base][tf] = pd.DataFrame()

# å…±æŒ¯é€»è¾‘å¤„ç†
rows = []
for base in CRYPTO_LIST:
    row = {"èµ„äº§": base}
    for g_name, g_tfs in RESONANCE_GROUPS.items():
        # è·å–è¯¥ç»„ä¸‰ä¸ªå‘¨æœŸçš„çŠ¶æ€
        states = []
        for tf in g_tfs:
            df = all_data[base].get(tf, pd.DataFrame())
            states.append(df.iloc[-1]['pos'] if not df.empty else "None")
        
        # åˆ¤æ–­æ˜¯å¦å…±æŒ¯
        is_res = len(set(states)) == 1 and states[0] != "None"
        res_dir = states[0] if is_res else "âŒ"
        row[g_name] = f"**{res_dir}**"
        
        # æ ¸å¿ƒï¼šã€å…±æŒ¯æ‰å‘ã€‘+ã€äº§ç”Ÿæ–°ä¿¡å·æ‰å‘ã€‘
        # åªè¦ç»„å†…ä»»ä½•ä¸€ä¸ªå‘¨æœŸåˆšåˆšå‘ç”Ÿäº†ä¿¡å·å˜æ›´ï¼Œä¸”å˜æ›´åè¾¾æˆäº†å…¨ç»„å…±æŒ¯ï¼Œå³æ¨é€
        for tf in g_tfs:
            df = all_data[base].get(tf, pd.DataFrame())
            if not df.empty and df.iloc[-1]['sig'] and is_res:
                sig_time = df.index[-1].astimezone(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
                cache_key = f"{base}_{g_name}_{res_dir}_{sig_time}"
                
                if cache_key not in st.session_state.sent_cache:
                    new_log = {"æ—¶é—´": sig_time, "èµ„äº§": base, "ç»„": g_name, "å…±æŒ¯æ–¹å‘": res_dir, "ä»·æ ¼": df.iloc[-1]['Close']}
                    st.session_state.alert_logs.insert(0, new_log)
                    save_log(new_log)
                    send_wx(f"ğŸš€{g_name}å…±æŒ¯: {base}", f"æ–¹å‘: {res_dir}\nä»·æ ¼: {new_log['ä»·æ ¼']}")
                    st.session_state.sent_cache.add(cache_key)

    rows.append(row)

# ==================== 4. ç•Œé¢æ¸²æŸ“ ====================
st.subheader("ğŸ”¥ ä¸¤ç»„å‘¨æœŸå…±æŒ¯å®æ—¶å¯¹æ¯”")
st.table(pd.DataFrame(rows))

st.divider()
st.subheader("ğŸ“œ å…±æŒ¯å†å²è®°å½• (æ”¯æŒå¸ç§/ç»„ç‹¬ç«‹ä¸‹è½½)")
if st.session_state.alert_logs:
    log_df = pd.DataFrame(st.session_state.alert_logs)
    for asset in sorted(log_df["èµ„äº§"].unique()):
        with st.expander(f"ğŸ“‚ {asset} å†å²ä¿¡å·"):
            asset_df = log_df[log_df["èµ„äº§"] == asset]
            st.dataframe(asset_df, use_container_width=True, hide_index=True)
            # æ¯ä¸ªå¸ç§ç‹¬ç«‹çš„ä¸‹è½½æŒ‰é’®
            csv = asset_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(f"ä¸‹è½½ {asset} æ—¥å¿—", csv, f"{asset}_res.csv", "text/csv", key=f"dl_{asset}")

st.sidebar.write(f"æœ€åæ›´æ–°: {datetime.now(BEIJING_TZ).strftime('%H:%M:%S')}")
time.sleep(300)
st.rerun()
