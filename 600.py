import streamlit as st
import pandas as pd
import numpy as np
import pandas_ta as ta
import ccxt
import asyncio
import aiohttp
import requests
from datetime import datetime, timedelta
import pytz
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache
import warnings
warnings.filterwarnings('ignore')

# ==================== 1. æ ¸å¿ƒé…ç½® ====================
APP_TOKEN = "AT_3H9akFZPvOE98cPrDydWmKM4ndgT3bVH"
USER_UID = "UID_wfbEjBobfoHNLmprN3Pi5nwWb4oM"

CRYPTO_LIST = ["BTC", "ETH", "SOL", "SUI", "RENDER", "DOGE", "XRP", "HYPE", "AAVE", "TAO", "XAG", "XAU"]
CONTRACTS = {"TAO", "XAG", "XAU"}
INTERVALS = ["1m", "5m", "15m", "30m", "1h", "4h", "1d"]
ALERT_INTERVALS = ["15m", "30m", "1h"]

# å®šä¹‰ä¸¤ä¸ªä¸‰å‘¨æœŸç»„
RESONANCE_GROUPS = {
    "group1": ["4h", "1h", "15m"],  # ç»„1: 4h, 1h, 15m
    "group2": ["1h", "15m", "5m"]   # ç»„2: 1h, 15m, 5m
}

BEIJING_TZ = pytz.timezone('Asia/Shanghai')

# ==================== 2. å¼‚æ­¥æ•°æ®è·å– ====================

class AsyncDataFetcher:
    def __init__(self):
        self.exchange = ccxt.okx({
            'enableRateLimit': True,
            'timeout': 30000,
            'session': aiohttp.ClientSession()
        })
        self.exchange.load_markets()
        self._cache = {}
        self._cache_time = {}
        self.CACHE_TTL = 30  # ç¼“å­˜30ç§’
        
    def _get_cache_key(self, base, timeframe):
        return f"{base}_{timeframe}"
    
    def _is_cache_valid(self, cache_key):
        if cache_key not in self._cache_time:
            return False
        return time.time() - self._cache_time[cache_key] < self.CACHE_TTL
    
    async def fetch_ohlcv_async(self, symbol, timeframe, limit=200):
        try:
            ohlcv = await self.exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)
            return ohlcv
        except Exception as e:
            print(f"Error fetching {symbol} {timeframe}: {e}")
            return None
    
    async def fetch_multiple_async(self, symbols_timeframes):
        """æ‰¹é‡è·å–å¤šä¸ªsymbolå’Œæ—¶é—´å‘¨æœŸçš„æ•°æ®"""
        tasks = []
        for symbol, timeframe in symbols_timeframes:
            tasks.append(self.fetch_ohlcv_async(symbol, timeframe))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        return results
    
    def fetch_all_data_batch(self, bases, timeframes):
        """æ‰¹é‡åŒæ­¥è·å–æ‰€æœ‰æ•°æ®"""
        all_data = {}
        
        # æ„å»ºè¦è·å–çš„æ‰€æœ‰symbolå’Œtimeframeç»„åˆ
        symbols_timeframes = []
        symbol_map = {}  # æ˜ å°„ç´¢å¼•åˆ°baseå’Œtimeframe
        
        for base in bases:
            all_data[base] = {}
            sym = f"{base}-USDT-SWAP" if base in CONTRACTS else f"{base}/USDT"
            
            for tf in timeframes:
                cache_key = self._get_cache_key(base, tf)
                
                # æ£€æŸ¥ç¼“å­˜
                if self._is_cache_valid(cache_key):
                    all_data[base][tf] = self._cache[cache_key]
                else:
                    symbols_timeframes.append((sym, tf))
                    idx = len(symbols_timeframes) - 1
                    symbol_map[idx] = (base, tf, sym)
        
        if not symbols_timeframes:
            return all_data
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è·å–
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = []
            for sym, tf in symbols_timeframes:
                future = executor.submit(self._fetch_sync, sym, tf)
                futures.append(future)
            
            for idx, future in enumerate(futures):
                if idx not in symbol_map:
                    continue
                    
                base, tf, sym = symbol_map[idx]
                try:
                    bars = future.result(timeout=10)
                    if bars and len(bars) > 0:
                        df = self._process_bars_to_df(bars)
                        cache_key = self._get_cache_key(base, tf)
                        self._cache[cache_key] = df
                        self._cache_time[cache_key] = time.time()
                        all_data[base][tf] = df
                    else:
                        all_data[base][tf] = pd.DataFrame()
                except Exception as e:
                    print(f"Error processing {base} {tf}: {e}")
                    all_data[base][tf] = pd.DataFrame()
        
        return all_data
    
    def _fetch_sync(self, symbol, timeframe, retries=3):
        """åŒæ­¥è·å–æ•°æ®ï¼Œå¸¦é‡è¯•"""
        for attempt in range(retries):
            try:
                bars = self.exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=200)
                return bars
            except Exception as e:
                if attempt == retries - 1:
                    print(f"Failed to fetch {symbol} {timeframe} after {retries} attempts: {e}")
                time.sleep(1 * (attempt + 1))  # æŒ‡æ•°é€€é¿
        return None
    
    def _process_bars_to_df(self, bars):
        """å¤„ç†barsæ•°æ®ä¸ºDataFrame"""
        if not bars or len(bars) == 0:
            return pd.DataFrame()
        
        df = pd.DataFrame(bars, columns=['ts','open','high','low','close','volume'])
        df['ts'] = pd.to_datetime(df['ts'], unit='ms').dt.tz_localize('UTC')
        df.set_index('ts', inplace=True)
        return df

# ==================== 3. é€»è¾‘å‡½æ•° ====================

def send_wx_pusher(title, body):
    if not APP_TOKEN or not USER_UID: return
    try:
        payload = {"appToken": APP_TOKEN, "content": f"{title}\n{body}", "uids": [USER_UID]}
        requests.post("https://wxpusher.zjiecode.com/api/send/message", json=payload, timeout=5)
    except Exception as e:
        print(f"æ¨é€å¤±è´¥: {e}")

@lru_cache(maxsize=100)
def calculate_indicators_cached(df_hash, sensitivity, atr_period):
    """ç¼“å­˜æŒ‡æ ‡è®¡ç®—"""
    return calculate_indicators(df_hash, sensitivity, atr_period)

def calculate_indicators(df, sensitivity, atr_period):
    if df.empty or len(df) < 50: 
        return pd.DataFrame()
    
    df.columns = [str(c).capitalize() for c in df.columns]
    
    # è®¡ç®—ATR
    df['atr'] = ta.atr(df['High'], df['Low'], df['Close'], length=atr_period)
    df = df.dropna(subset=['atr']).copy()
    
    if df.empty:
        return pd.DataFrame()
    
    n_loss = sensitivity * df['atr']
    src = df['Close']
    trail_stop = np.zeros(len(df))
    
    # åˆå§‹åŒ–ç¬¬ä¸€ä¸ªå€¼
    if len(df) > 0:
        trail_stop[0] = src.iloc[0] - n_loss.iloc[0]
    
    # å‘é‡åŒ–è®¡ç®—ï¼ˆæ¯”å¾ªç¯å¿«ï¼‰
    for i in range(1, len(df)):
        p = trail_stop[i-1]
        src_i = src.iloc[i]
        src_i_1 = src.iloc[i-1]
        n_loss_i = n_loss.iloc[i]
        
        if src_i > p and src_i_1 > p:
            trail_stop[i] = max(p, src_i - n_loss_i)
        elif src_i < p and src_i_1 < p:
            trail_stop[i] = min(p, src_i + n_loss_i)
        elif src_i > p:
            trail_stop[i] = src_i - n_loss_i
        else:
            trail_stop[i] = src_i + n_loss_i
    
    df['trail_stop'] = trail_stop
    df['buy_signal'] = (df['Close'] > df['trail_stop']) & (df['Close'].shift(1) <= df['trail_stop'].shift(1))
    df['sell_signal'] = (df['Close'] < df['trail_stop']) & (df['Close'].shift(1) >= df['trail_stop'].shift(1))
    
    # è®¡ç®—OBVå’Œæˆäº¤é‡å‡å€¼
    df['obv'] = ta.obv(df['Close'], df['Volume'])
    df['vol_avg'] = df['Volume'].shift(1).rolling(window=5, min_periods=1).mean()
    
    return df

def calculate_win_rate(log_df, action_col='åŠ¨ä½œ', profit_col='ç›ˆäº'):
    if log_df.empty:
        return {"win_rate": "0.0%", "total_trades": 0, "wins": 0, "losses": 0}
    
    if action_col not in log_df.columns or profit_col not in log_df.columns:
        return {"win_rate": "N/A (æ— äº¤æ˜“è®°å½•)", "total_trades": 0, "wins": 0, "losses": 0}
    
    # å‘é‡åŒ–è¿‡æ»¤
    closed_mask = (
        log_df[action_col].astype(str).str.contains('å¹³', na=False) &
        (log_df[profit_col] != '-') &
        (log_df[profit_col] != '') &
        log_df[profit_col].notna()
    )
    
    closed_trades = log_df[closed_mask].copy()
    
    if closed_trades.empty:
        return {"win_rate": "0.0% (æ— å¹³ä»“è®°å½•)", "total_trades": 0, "wins": 0, "losses": 0}
    
    # ä½¿ç”¨å‘é‡åŒ–è½¬æ¢
    def safe_float_series(x):
        try:
            return pd.to_numeric(x.astype(str).str.rstrip('%'), errors='coerce')
        except:
            return pd.Series([np.nan] * len(x))
    
    closed_trades['profit'] = safe_float_series(closed_trades[profit_col])
    closed_trades = closed_trades.dropna(subset=['profit'])
    
    if closed_trades.empty:
        return {"win_rate": "0.0%", "total_trades": 0, "wins": 0, "losses": 0}
    
    wins = (closed_trades['profit'] > 0).sum()
    losses = (closed_trades['profit'] <= 0).sum()
    total = wins + losses
    win_rate = (wins / total * 100) if total > 0 else 0.0
    
    return {
        "win_rate": f"{win_rate:.1f}%",
        "total_trades": total,
        "wins": wins,
        "losses": losses
    }

# ==================== 4. ä¸»ç¨‹åº ====================

st.set_page_config(page_title="UT Bot Pro æ€§èƒ½ä¼˜åŒ–ç‰ˆ", layout="wide")

# åˆå§‹åŒ–çŠ¶æ€
if "last_update" not in st.session_state:
    st.session_state.last_update = time.time()
    st.session_state.data_fetcher = AsyncDataFetcher()
    st.session_state.all_data_cache = {}
    st.session_state.cache_time = 0
    st.session_state.sent_cache = {}
    st.session_state.alert_logs = []
    st.session_state.positions = {}

refresh_sec = 300 
time_passed = time.time() - st.session_state.last_update

# ä¾§è¾¹æ 
st.sidebar.title("âš™ï¸ è®¾ç½®")
st.sidebar.caption(f"ğŸ”„ åˆ·æ–°å€’è®¡æ—¶: {max(0, int(refresh_sec - time_passed))}s")

selected_cryptos = st.sidebar.multiselect(
    "å“ç§é€‰æ‹©", 
    CRYPTO_LIST, 
    default=CRYPTO_LIST[:5]  # é»˜è®¤é€‰å‰5ä¸ªåŠ å¿«åŠ è½½
)

sens = st.sidebar.slider("æ•æ„Ÿåº¦", 0.1, 5.0, 1.0, 0.1)
atrp = st.sidebar.slider("ATRå‘¨æœŸ", 1, 30, 10, 1)

# è‡ªåŠ¨åˆ·æ–°æŒ‰é’®
if st.sidebar.button("ğŸ”„ æ‰‹åŠ¨åˆ·æ–°æ•°æ®"):
    st.session_state.cache_time = 0  # æ¸…é™¤ç¼“å­˜
    st.rerun()

# æ‰¹é‡è·å–æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰
cache_key = f"{'_'.join(selected_cryptos)}_{sens}_{atrp}"
if (time.time() - st.session_state.cache_time > 60 or 
    cache_key not in st.session_state.all_data_cache):
    
    with st.spinner(f"æ­£åœ¨è·å–{len(selected_cryptos)}ä¸ªå“ç§æ•°æ®..."):
        fetcher = st.session_state.data_fetcher
        all_data = fetcher.fetch_all_data_batch(selected_cryptos, INTERVALS)
        
        # è®¡ç®—æŒ‡æ ‡
        for base in selected_cryptos:
            for tf in INTERVALS:
                if tf in all_data[base] and not all_data[base][tf].empty:
                    all_data[base][tf] = calculate_indicators(all_data[base][tf], sens, atrp)
        
        st.session_state.all_data_cache[cache_key] = all_data
        st.session_state.cache_time = time.time()
        st.session_state.last_update = time.time()

all_data = st.session_state.all_data_cache.get(cache_key, {})

# æ„å»ºå±•ç¤ºæ•°æ®
rows = []
for base in selected_cryptos:
    price_now = "N/A"
    base_data = all_data.get(base, {})
    
    # è·å–æœ€æ–°ä»·æ ¼
    for t_val in ["1m", "5m", "15m"]:
        df = base_data.get(t_val, pd.DataFrame())
        if not df.empty:
            price_now = df.iloc[-1]['Close']
            break
    
    row_data = {"èµ„äº§": base, "å®æ—¶ä»·æ ¼": f"<b>{price_now}</b>"}
    
    for tf in INTERVALS:
        df = base_data.get(tf, pd.DataFrame())
        if df.empty:
            row_data[tf] = "-"
            continue
        
        latest = df.iloc[-1]
        color = "#00ff00" if latest['Close'] > latest['trail_stop'] else "#ff0000"
        status_text = "BUY ğŸŸ¢" if color == "#00ff00" else "SELL ğŸ”´"
        row_data[tf] = f"<div style='color:{color}; font-weight:bold;'>{status_text}</div><div style='font-size:0.8em; color:#888;'>æ­¢æŸ:{latest['trail_stop']:.2f}</div>"
        
        # ä¿¡å·åˆ¤æ–­ + æŒä»“ç®¡ç†
        if tf in ALERT_INTERVALS and len(df) >= 2:
            prev = df.iloc[-2]
            curr = df.iloc[-1]
            
            buy_cross = (curr['Close'] > curr['trail_stop']) and (prev['Close'] <= prev['trail_stop'])
            sell_cross = (curr['Close'] < curr['trail_stop']) and (prev['Close'] >= prev['trail_stop'])
            
            signal = "NONE"
            if buy_cross: 
                signal = "BUY ğŸŸ¢"
            elif sell_cross: 
                signal = "SELL ğŸ”´"
            
            if signal != "NONE":
                sig_time_utc = df.index[-2]
                sig_time_beijing = sig_time_utc.astimezone(BEIJING_TZ)
                sig_time_str = sig_time_beijing.strftime('%Y-%m-%d %H:%M:%S')
                cache_key = f"{base}_{tf}_{sig_time_str}"
                
                if cache_key not in st.session_state.sent_cache:
                    # è®¡ç®—æˆäº¤é‡æ¯”ç‡
                    vol_r = prev['Volume'] / prev['vol_avg'] if prev['vol_avg'] > 0 else 1.0
                    vol_tag = "âš¡æ”¾é‡" if vol_r >= 1.2 else "â˜ï¸ç¼©é‡"
                    
                    # è®¡ç®—OBVæ–¹å‘
                    obv_up = prev['obv'] > df['obv'].iloc[-3] if len(df) >= 3 else False
                    obv_tag = "ğŸ“ˆæµå…¥" if obv_up else "ğŸ“‰æµå‡º"
                    
                    # ä¸‰å‘¨æœŸå…±æŒ¯æ£€æŸ¥
                    sync_tags = {}
                    for group_name, group_tfs in RESONANCE_GROUPS.items():
                        if tf in group_tfs:
                            group_statuses = []
                            for g_tf in group_tfs:
                                g_df = all_data.get(base, {}).get(g_tf, pd.DataFrame())
                                if not g_df.empty:
                                    g_status = "BUY" if g_df.iloc[-1]['Close'] > g_df.iloc[-1]['trail_stop'] else "SELL"
                                    group_statuses.append(g_status)
                            
                            if len(group_statuses) == len(group_tfs):
                                if all(s == "BUY" for s in group_statuses) and signal == "BUY ğŸŸ¢":
                                    sync_tags[group_name] = "ğŸ”—å…±æŒ¯ (åšå¤š)"
                                elif all(s == "SELL" for s in group_statuses) and signal == "SELL ğŸ”´":
                                    sync_tags[group_name] = "ğŸ”—å…±æŒ¯ (åšç©º)"
                                else:
                                    sync_tags[group_name] = "âš ï¸æ— å…±æŒ¯"
                            else:
                                sync_tags[group_name] = "âš ï¸æ•°æ®ä¸è¶³"
                    
                    # æŒä»“é€»è¾‘
                    action_descs = {}
                    profit_strs = {}
                    
                    for group_name in RESONANCE_GROUPS:
                        pos_key = f"{base}_{tf}_{group_name}"
                        if pos_key not in st.session_state.positions:
                            st.session_state.positions[pos_key] = {"side": "flat", "entry_price": None, "entry_time": None}
                        
                        pos = st.session_state.positions[pos_key]
                        action_desc = ""
                        profit_str = ""
                        
                        if group_name in sync_tags and "å…±æŒ¯" in sync_tags[group_name]:
                            if "åšå¤š" in sync_tags[group_name]:
                                if pos["side"] == "long":
                                    action_desc = "ç»§ç»­æŒå¤š"
                                elif pos["side"] == "short":
                                    if pos["entry_price"] is not None:
                                        profit_pct = (pos["entry_price"] - curr['Close']) / pos["entry_price"] * 100
                                        profit_str = f"{profit_pct:+.2f}%"
                                    action_desc = f"å¹³ç©ºè½¬å¤šï¼ˆç›ˆäº {profit_str or 'æœªçŸ¥'}ï¼‰"
                                    st.session_state.positions[pos_key] = {
                                        "side": "long",
                                        "entry_price": curr['Close'],
                                        "entry_time": sig_time_str
                                    }
                                else:
                                    action_desc = "å¼€å¤š"
                                    st.session_state.positions[pos_key] = {
                                        "side": "long",
                                        "entry_price": curr['Close'],
                                        "entry_time": sig_time_str
                                    }
                            
                            elif "åšç©º" in sync_tags[group_name]:
                                if pos["side"] == "short":
                                    action_desc = "ç»§ç»­æŒç©º"
                                elif pos["side"] == "long":
                                    if pos["entry_price"] is not None:
                                        profit_pct = (curr['Close'] - pos["entry_price"]) / pos["entry_price"] * 100
                                        profit_str = f"{profit_pct:+.2f}%"
                                    action_desc = f"å¹³å¤šè½¬ç©ºï¼ˆç›ˆäº {profit_str or 'æœªçŸ¥'}ï¼‰"
                                    st.session_state.positions[pos_key] = {
                                        "side": "short",
                                        "entry_price": curr['Close'],
                                        "entry_time": sig_time_str
                                    }
                                else:
                                    action_desc = "å¼€ç©º"
                                    st.session_state.positions[pos_key] = {
                                        "side": "short",
                                        "entry_price": curr['Close'],
                                        "entry_time": sig_time_str
                                    }
                        else:
                            if pos["side"] != "flat":
                                if pos["side"] == "long":
                                    profit_pct = (curr['Close'] - pos["entry_price"]) / pos["entry_price"] * 100
                                else:
                                    profit_pct = (pos["entry_price"] - curr['Close']) / pos["entry_price"] * 100
                                profit_str = f"{profit_pct:+.2f}%"
                                action_desc = f"æ— å…±æŒ¯å¹³ä»“ï¼ˆ{pos['side']} ç›ˆäº {profit_str}ï¼‰"
                                st.session_state.positions[pos_key] = {"side": "flat", "entry_price": None, "entry_time": None}
                            else:
                                action_desc = "è§‚æœ›ä¸­ï¼ˆæ— æŒä»“ï¼‰"
                        
                        action_descs[group_name] = action_desc
                        profit_strs[group_name] = profit_str
                    
                    # æ—¥å¿—è®°å½•
                    log_entry = {
                        "æ—¶é—´": sig_time_str,
                        "èµ„äº§": base, 
                        "å‘¨æœŸ": tf, 
                        "ä¿¡å·": signal,
                        "èƒ½é‡": f"{vol_r:.1f}x {vol_tag}",
                        "OBV": obv_tag,
                        "ä¿¡å·ä»·æ ¼": curr['Close'],
                        "æœ€æ–°ä»·æ ¼": price_now,
                        "æ­¢æŸ": latest['trail_stop'],
                        "ATR": latest['atr'],
                        "æˆäº¤é‡": latest['Volume'],
                        "OBVå€¼": latest['obv']
                    }
                    
                    for group_name in RESONANCE_GROUPS:
                        log_entry[f"{group_name}_å…±æŒ¯"] = sync_tags.get(group_name, "N/A")
                        log_entry[f"{group_name}_åŠ¨ä½œ"] = action_descs.get(group_name, "æ— åŠ¨ä½œ")
                        log_entry[f"{group_name}_ç›ˆäº"] = profit_strs.get(group_name, "-")
                    
                    st.session_state.alert_logs.insert(0, log_entry)
                    
                    # æ¨é€
                    push_title = f"{base}({tf}){signal}|{vol_tag}"
                    push_body = f"ä»·æ ¼:{curr['Close']:.2f}\n{obv_tag}"
                    for group_name in RESONANCE_GROUPS:
                        push_body += f"\n{group_name}: {sync_tags.get(group_name, 'N/A')} | {action_descs.get(group_name, '')} | ç›ˆäº {profit_strs.get(group_name, '-')}"
                    
                    send_wx_pusher(push_title, push_body)
                    st.session_state.sent_cache[cache_key] = True
    
    rows.append(row_data)

# ==================== 5. æ¸²æŸ“ç•Œé¢ ====================

st.markdown("<h3 style='text-align:center;'>ğŸš€ UT Bot å¤šé‡è¿‡æ»¤ç³»ç»Ÿ (æ€§èƒ½ä¼˜åŒ–ç‰ˆ)</h3>", unsafe_allow_html=True)

if rows:
    disp_df = pd.DataFrame(rows)
    st.write(disp_df[["èµ„äº§", "å®æ—¶ä»·æ ¼"] + INTERVALS].to_html(escape=False, index=False), unsafe_allow_html=True)

st.divider()
st.subheader("ğŸ“œ æ¨é€æ—¥å¿— - è¿‘24å°æ—¶")

if st.session_state.alert_logs:
    log_df = pd.DataFrame(st.session_state.alert_logs)
    
    required_cols = ["æ—¶é—´", "èµ„äº§", "å‘¨æœŸ", "ä¿¡å·", "èƒ½é‡", "OBV", "ä¿¡å·ä»·æ ¼", "æœ€æ–°ä»·æ ¼", "æ­¢æŸ", "ATR", "æˆäº¤é‡", "OBVå€¼"]
    for group in RESONANCE_GROUPS:
        required_cols += [f"{group}_å…±æŒ¯", f"{group}_åŠ¨ä½œ", f"{group}_ç›ˆäº"]
    
    available_cols = [col for col in required_cols if col in log_df.columns]
    log_df = log_df[available_cols].copy()
    
    # æ—¶é—´è§£æ
    log_df['æ—¶é—´_dt'] = pd.to_datetime(log_df['æ—¶é—´'], format='%Y-%m-%d %H:%M:%S', errors='coerce')
    if log_df['æ—¶é—´_dt'].dt.tz is None:
        log_df['æ—¶é—´_dt'] = log_df['æ—¶é—´_dt'].dt.tz_localize(BEIJING_TZ, ambiguous='NaT', nonexistent='NaT')
    
    now_beijing = datetime.now(BEIJING_TZ)
    threshold = now_beijing - timedelta(hours=24)
    recent_df = log_df[log_df['æ—¶é—´_dt'] >= threshold].copy()
    
    if recent_df.empty:
        st.info("è¿‘24å°æ—¶å†…æš‚æ— æ¨é€è®°å½•")
    else:
        recent_df = recent_df.sort_values("æ—¶é—´_dt", ascending=False).reset_index(drop=True)
        st.caption(f"å…± {len(recent_df)} æ¡ä¿¡å· | æ—¶é—´èŒƒå›´ï¼š{threshold.strftime('%Y-%m-%d %H:%M')} â†’ {now_beijing.strftime('%Y-%m-%d %H:%M')}")
        
        # èƒœç‡ç»Ÿè®¡
        if 'åŠ¨ä½œ' in recent_df.columns and 'ç›ˆäº' in recent_df.columns:
            global_stats = calculate_win_rate(recent_df, action_col='åŠ¨ä½œ', profit_col='ç›ˆäº')
            st.markdown(f"**å…¨å±€èƒœç‡ç»Ÿè®¡**ï¼šèƒœç‡ {global_stats['win_rate']} | æ€»äº¤æ˜“ {global_stats['total_trades']} | èƒœ {global_stats['wins']} | è´Ÿ {global_stats['losses']}")
        
        for group in RESONANCE_GROUPS:
            group_action_col = f"{group}_åŠ¨ä½œ"
            group_profit_col = f"{group}_ç›ˆäº"
            if group_action_col in recent_df.columns and group_profit_col in recent_df.columns:
                group_stats = calculate_win_rate(recent_df, action_col=group_action_col, profit_col=group_profit_col)
                st.markdown(f"**{group} èƒœç‡ç»Ÿè®¡**ï¼šèƒœç‡ {group_stats['win_rate']} | æ€»äº¤æ˜“ {group_stats['total_trades']} | èƒœ {group_stats['wins']} | è´Ÿ {group_stats['losses']}")
        
        # æŒ‰å¸ç§æ˜¾ç¤º
        assets = sorted(recent_df["èµ„äº§"].unique())
        
        for asset in assets:
            asset_df = recent_df[recent_df["èµ„äº§"] == asset]
            
            with st.expander(f"ğŸ“ˆ {asset} ï¼ˆ{len(asset_df)} æ¡ä¿¡å·ï¼‰", expanded=(len(assets) <= 5)):
                periods = sorted(asset_df["å‘¨æœŸ"].unique(), key=lambda x: INTERVALS.index(x) if x in INTERVALS else len(INTERVALS))
                
                for period in periods:
                    period_df = asset_df[asset_df["å‘¨æœŸ"] == period].copy()
                    
                    st.markdown(f"**{period}** ï¼ˆ{len(period_df)} æ¡ï¼‰")
                    
                    display_cols = [c for c in required_cols[3:] if c in period_df.columns]
                    display_cols = ["æ—¶é—´", "ä¿¡å·"] + display_cols
                    
                    st.dataframe(
                        period_df[display_cols],
                        use_container_width=True,
                        hide_index=True,
                        column_config={
                            "ç›ˆäº": st.column_config.TextColumn("ç›ˆäº", width="small"),
                            "åŠ¨ä½œ": st.column_config.TextColumn("åŠ¨ä½œ", width="medium"),
                            "ä¿¡å·ä»·æ ¼": st.column_config.NumberColumn("ä¿¡å·ä»·æ ¼", format="%.4f"),
                            "æœ€æ–°ä»·æ ¼": st.column_config.NumberColumn("æœ€æ–°ä»·æ ¼", format="%.4f"),
                            "æ­¢æŸ": st.column_config.NumberColumn("æ­¢æŸ", format="%.4f"),
                            "ATR": st.column_config.NumberColumn("ATR", format="%.4f")
                        }
                    )
                    
                    # ä¸‹è½½æŒ‰é’®
                    if not period_df.empty:
                        csv_period = period_df.drop(columns=['æ—¶é—´_dt', 'èµ„äº§', 'å‘¨æœŸ'], errors='ignore').to_csv(index=False).encode('utf-8-sig')
                        file_name = f"{asset}_{period}_24h_{now_beijing.strftime('%Y%m%d_%H%M')}.csv"
                        
                        st.download_button(
                            label=f"ä¸‹è½½ {asset} {period} ï¼ˆCSVï¼‰",
                            data=csv_period,
                            file_name=file_name,
                            mime="text/csv",
                            key=f"dl_{asset}_{period}_{time.time()}"
                        )
                    
                    st.markdown("---")
        
        # å…¨å±€ä¸‹è½½
        st.markdown("### å…¨éƒ¨è¿‘24å°æ—¶ä¸‹è½½")
        csv_all = recent_df.drop(columns=['æ—¶é—´_dt'], errors='ignore').to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ä¸‹è½½å…¨éƒ¨ï¼ˆCSVï¼‰",
            data=csv_all,
            file_name=f"utbot_all_24h_{now_beijing.strftime('%Y%m%d_%H%M')}.csv",
            mime="text/csv",
            key="dl_all_csv"
        )
else:
    st.info("æš‚æ— æ¨é€æ—¥å¿—")

# æ€§èƒ½ä¿¡æ¯
st.sidebar.divider()
st.sidebar.caption("ğŸ“Š æ€§èƒ½ä¿¡æ¯")
st.sidebar.caption(f"æ•°æ®è·å–è€—æ—¶: {time.time() - st.session_state.cache_time:.1f}s")
st.sidebar.caption(f"ç¼“å­˜å‘½ä¸­ç‡: {len(st.session_state.sent_cache)} æ¡å·²æ¨é€")
st.sidebar.caption(f"æŒä»“æ•°é‡: {len(st.session_state.positions)}")

# æ¸…é™¤ç¼“å­˜æŒ‰é’®
if st.sidebar.button("ğŸ§¹ æ¸…é™¤ç¼“å­˜"):
    st.session_state.cache_time = 0
    st.session_state.sent_cache.clear()
    st.session_state.all_data_cache.clear()
    st.rerun()
