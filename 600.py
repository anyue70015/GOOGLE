import streamlit as st
import pandas as pd
import numpy as np
import pandas_ta as ta
import ccxt
import requests
import os
from datetime import datetime, timedelta
import pytz
import time

# ==================== 1. æ ¸å¿ƒé…ç½® ====================
APP_TOKEN = "AT_3H9akFZPvOE98cPrDydWmKM4ndgT3bVH"
USER_UID = "UID_wfbEjBobfoHNLmprN3Pi5nwWb4oM"
LOG_FILE = "trade_resonance_master.csv"

# TAO, XAG, XAU æ˜¯åˆçº¦ï¼Œå…¶ä½™æ˜¯ç°è´§
CRYPTO_LIST = ["BTC", "ETH", "SOL", "SUI", "RENDER", "DOGE", "XRP", "HYPE", "AAVE", "TAO", "XAG", "XAU"]
CONTRACTS = {"TAO", "XAG", "XAU"}

# ä½ è¦æ±‚çš„ä¸¤ç»„å¯¹æ¯” (å•ä½ï¼šåˆ†é’Ÿ)
RESONANCE_GROUPS = {
    "Group1_æ—¥å†…(5-15-60)": ["5m", "15m", "1h"],
    "Group2_è¶‹åŠ¿(15-60-240)": ["15m", "1h", "4h"]
}

INTERVALS = ["5m", "15m", "1h", "4h"]
BEIJING_TZ = pytz.timezone('Asia/Shanghai')

# ==================== 2. æŒä¹…åŒ–ä¸æ ¸å¿ƒç®—æ³• ====================

def load_logs():
    if os.path.exists(LOG_FILE):
        try: return pd.read_csv(LOG_FILE).to_dict('records')
        except: return []
    return []

def save_log_to_disk(entry):
    df = pd.DataFrame([entry])
    header = not os.path.exists(LOG_FILE)
    df.to_csv(LOG_FILE, mode='a', index=False, header=header, encoding='utf-8-sig')

def calculate_ut_bot(df, sensitivity, atr_period):
    if df.empty or len(df) < 50: return pd.DataFrame()
    df.columns = [str(c).capitalize() for c in df.columns]
    df['atr'] = ta.atr(df['High'], df['Low'], df['Close'], length=atr_period)
    df = df.dropna(subset=['atr']).copy()
    n_loss = sensitivity * df['atr']
    src, trail_stop = df['Close'], np.zeros(len(df))
    for i in range(1, len(df)):
        p = trail_stop[i-1]
        if src.iloc[i] > p and src.iloc[i-1] > p: trail_stop[i] = max(p, src.iloc[i] - n_loss.iloc[i])
        elif src.iloc[i] < p and src.iloc[i-1] < p: trail_stop[i] = min(p, src.iloc[i] + n_loss.iloc[i])
        else: trail_stop[i] = src.iloc[i] - n_loss.iloc[i] if src.iloc[i] > p else src.iloc[i] + n_loss.iloc[i]
    df['ts'] = trail_stop
    df['pos'] = np.where(df['Close'] > df['ts'], "BUY", "SELL")
    df['sig_change'] = (df['pos'] != df['pos'].shift(1))
    return df

def send_wx(title, body):
    try:
        payload = {"appToken": APP_TOKEN, "content": f"{title}\n{body}", "uids": [USER_UID]}
        requests.post("https://wxpusher.zjiecode.com/api/send/message", json=payload, timeout=5)
    except: pass

# ==================== 3. ä¸»ç¨‹åºé€»è¾‘ ====================
st.set_page_config(page_title="UT Bot ä¸¤ç»„å…±æŒ¯å¯¹æ¯”ç³»ç»Ÿ", layout="wide")

if "alert_logs" not in st.session_state:
    st.session_state.alert_logs = load_logs()
if "sent_cache" not in st.session_state:
    # å¯åŠ¨æ—¶æ ¹æ®å†å²è®°å½•å¡«å……ç¼“å­˜ï¼Œé˜²æ­¢é‡å¯é‡å¤å‘é€
    st.session_state.sent_cache = {f"{l['èµ„äº§']}_{l['ç»„åˆ«']}_{l['æ—¶é—´'][:16]}" for l in st.session_state.alert_logs}

ex = ccxt.okx({'enableRateLimit': True})
sens = st.sidebar.slider("æ•æ„Ÿåº¦", 0.1, 5.0, 1.2)
atrp = st.sidebar.slider("ATRå‘¨æœŸ", 1, 30, 10)
refresh_sec = st.sidebar.selectbox("åˆ·æ–°é¢‘ç‡", [60, 300, 600], index=1)

# æ•°æ®è·å–
all_data = {}
for base in CRYPTO_LIST:
    sym = f"{base}-USDT-SWAP" if base in CONTRACTS else f"{base}/USDT"
    all_data[base] = {}
    for tf in INTERVALS:
        try:
            bars = ex.fetch_ohlcv(sym, timeframe=tf, limit=100)
            df = pd.DataFrame(bars, columns=['ts','open','high','low','close','volume'])
            df.set_index(pd.to_datetime(df['ts'], unit='ms').dt.tz_localize('UTC'), inplace=True)
            all_data[base][tf] = calculate_ut_bot(df, sens, atrp)
        except: all_data[base][tf] = pd.DataFrame()

# æ ¸å¿ƒï¼šä¿¡å·å¤„ç†ä¸å…±æŒ¯å¯¹æ¯”
rows = []
for base in CRYPTO_LIST:
    p_15m = all_data[base].get("15m", pd.DataFrame())
    price_now = p_15m.iloc[-1]['Close'] if not p_15m.empty else "N/A"
    row = {"èµ„äº§": base, "å®æ—¶ä»·æ ¼": f"<b>{price_now}</b>"}

    for g_name, g_tfs in RESONANCE_GROUPS.items():
        # æå–è¯¥ç»„çŠ¶æ€
        states = []
        is_data_ok = True
        for tf in g_tfs:
            df = all_data[base].get(tf, pd.DataFrame())
            if not df.empty: states.append(df.iloc[-1]['pos'])
            else: is_data_ok = False; break
        
        # ä¸¥æ ¼å…±æŒ¯åˆ¤å®š
        is_res = is_data_ok and len(set(states)) == 1
        res_dir = states[0] if is_res else "None"
        
        # çœ‹æ¿é¢œè‰²
        color = "#00ff00" if res_dir == "BUY" else "#ff0000" if res_dir == "SELL" else "#888"
        row[g_name] = f"<span style='color:{color};font-weight:bold;'>{res_dir}</span>"
        
        # å‘é€è§¦å‘é€»è¾‘ï¼šå…±æŒ¯è¾¾æˆ + è‡³å°‘æœ‰ä¸€ä¸ªå‘¨æœŸåˆšå‡ºä¿¡å·
        if is_res:
            has_new_sig = any([all_data[base][tf].iloc[-1]['sig_change'] for tf in g_tfs if not all_data[base][tf].empty])
            if has_new_sig:
                sig_time = datetime.now(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
                cache_key = f"{base}_{g_name}_{sig_time[:16]}"
                
                if cache_key not in st.session_state.sent_cache:
                    log_entry = {"æ—¶é—´": sig_time, "èµ„äº§": base, "ç»„åˆ«": g_name, "æ–¹å‘": res_dir, "ä»·æ ¼": price_now}
                    st.session_state.alert_logs.insert(0, log_entry)
                    save_log_to_disk(log_entry)
                    send_wx(f"ğŸš€{g_name}å…±æŒ¯: {base}", f"æ–¹å‘: {res_dir}\nä»·æ ¼: {price_now}")
                    st.session_state.sent_cache.add(cache_key)
    rows.append(row)

# ==================== 4. æ¸²æŸ“ ====================
st.markdown("<h3 style='text-align:center;'>ğŸš€ UT Bot ä¸¤ç»„å‘¨æœŸå…±æŒ¯å¯¹æ¯”çœ‹æ¿</h3>", unsafe_allow_html=True)
st.write(pd.DataFrame(rows).to_html(escape=False, index=False), unsafe_allow_html=True)

st.divider()
st.subheader("ğŸ“œ åˆ†ç»„å…±æŒ¯å†å²æ—¥å¿—")

if st.session_state.alert_logs:
    df_logs = pd.DataFrame(st.session_state.alert_logs)
    tab1, tab2 = st.tabs(["Group1 æ—¥å†…è®°å½• (5-15-60)", "Group2 è¶‹åŠ¿è®°å½• (15-60-240)"])
    
    with tab1:
        g1_data = df_logs[df_logs["ç»„åˆ«"].str.contains("Group1")]
        if not g1_data.empty:
            for asset in sorted(g1_data["èµ„äº§"].unique()):
                with st.expander(f"ğŸ“¦ {asset} G1 å†å²"):
                    a_df = g1_data[g1_data["èµ„äº§"] == asset]
                    st.dataframe(a_df, use_container_width=True, hide_index=True)
                    st.download_button(f"å¯¼å‡º {asset} G1", a_df.to_csv(index=False).encode('utf-8-sig'), f"{asset}_G1.csv", "text/csv", key=f"dl_g1_{asset}")
        else: st.info("Group1 æš‚æ— ä¿¡å·")

    with tab2:
        g2_data = df_logs[df_logs["ç»„åˆ«"].str.contains("Group2")]
        if not g2_data.empty:
            for asset in sorted(g2_data["èµ„äº§"].unique()):
                with st.expander(f"ğŸ“¦ {asset} G2 å†å²"):
                    a_df = g2_data[g2_data["èµ„äº§"] == asset]
                    st.dataframe(a_df, use_container_width=True, hide_index=True)
                    st.download_button(f"å¯¼å‡º {asset} G2", a_df.to_csv(index=False).encode('utf-8-sig'), f"{asset}_G2.csv", "text/csv", key=f"dl_g2_{asset}")
        else: st.info("Group2 æš‚æ— ä¿¡å·")
else:
    st.info("ç³»ç»Ÿç›‘æ§ä¸­ï¼Œç­‰å¾…ä¸¥æ ¼å…±æŒ¯ä¿¡å·è§¦å‘...")

st.sidebar.caption(f"æœ€ååˆ·æ–°: {datetime.now(BEIJING_TZ).strftime('%H:%M:%S')}")
time.sleep(refresh_sec)
st.rerun()
